# Adrian Chavez-Loya  
**Data & Analytics Engineer**

I consider myself an analytics engineer because I thrive on connecting data engineering with analytics. I want to be involved in the entire data journey, from the initial source systems all the way to the final insights and dashboards that drive business decisions.

I enjoy building scalable data systems that transform raw, messy data into reliable, analytics ready datasets using ETL/ELT processes, data warehousing, and solid modeling practices.

I'm fascinated by how data moves through organizations and becomes actionable intelligence. I've become comfortable working with various tools and technologies including Python, SQL, Tableau, Power BI, and PySpark. I'm always exploring new techniques and tools for different business needs, currently diving into DuckDB, Apache Airflow, and streaming technologies like Kafka and Flink.

This field constantly evolves and I'm committed to continuous learning, currently focusing on pipeline automation, data quality, and building cloud data stacks that make analytics seamless and decision making more effective.

---

## About Me

- Graduate student in Management Information Systems (M.S.) at *Utah State University* (4.0 GPA) and International Commerce at *Seoul National University*
- Fluent in English, Korean, and Spanish  
- Based in Korea, originally from Salt Lake City, Utah

---

## Certifications

- **AWS Certified Data Engineer – Associate**  
- **Snowflake SnowPro Core Certification**  
- **Tableau Desktop Certified Professional**  
- **Professional Scrum Master I (PSM I)**  
- **TOPIK Level 6 (Advanced Korean Proficiency)**  

---

## Featured Repositories

| Repository | Description | Tech Stack |
|:--|:--|:--|
| [**AWS Data ETL Health & Mortality Analysis Project**](https://github.com/adrianc7/aws-data-etl-health-mortality-analysis-project) | Serverless AWS ETL pipeline analyzing PAHO/WHO health indicators across the Americas. Built a multi-stage workflow integrating data ingestion, transformation, and visualization using serverless compute. | AWS S3 · AWS Glue · Athena · PySpark · Tableau · Data Lake Architecture · ETL Orchestration |
| [**Sam's Subs Data Warehouse (dbt + Snowflake)**](https://github.com/adrianc7/sams-subs-datawarehouse) | Designed a modern ELT architecture using Airbyte for ingestion from SQL Server into Snowflake. Applied dbt transformations and built Tableau dashboards to analyze sales, orders, and customer engagement. | Snowflake · dbt · Airbyte · SQL Server · Tableau · Dimensional Modeling · ELT Orchestration |
| [**Spotify AWS Scalable Data Pipeline**](https://github.com/adrianc7/spotify-aws-scalable-data-pipeline) | Scalable data pipeline for Spotify API data built on AWS. Automated ingestion, schema discovery, transformation, and querying to extract insights on music listening trends. | AWS Lambda · S3 · Glue Crawlers · DataBrew · Athena · REST API Integration · Serverless ETL |
| [**Jetflix Snowflake Data Mart**](https://github.com/adrianc7/jetflix-snowflake-data-mart) | Built a complete ELT data pipeline and dimensional model for Jetflix, a mock streaming service. Designed OLTP-to-OLAP transformation using dbt in Snowflake and integrated AWS S3 as external stage storage. | Snowflake · dbt · SQL · AWS S3 · Lucidchart · Star Schema Design · Incremental Models |
| [**Iron Will Sportsbook Data Mart**](https://github.com/adrianc7/ironwill-sportsbook-datamart) | Developed a PostgreSQL data mart combining SQL Server betting logs and NFL datasets. Built a Python ETL pipeline to extract, transform, and load structured data for profitability analytics, testing, and regression modeling on customer value and personality insights. | PostgreSQL · Python · pandas · psycopg2 · AWS RDS · SQL Server · Data Normalization · Regression Analysis · Feature Engineering |
| [**Key Indicators: Life Expectancy Analysis**](https://github.com/adrianc7/machine-learning-projects/tree/main/life-expectancy-key-indicators) | Regression-based study of WHO/UN global health data (2000–2015). Modeled the effects of socioeconomic, health, and education factors on life expectancy using multivariate and polynomial regression. | Python · pandas · statsmodels · seaborn · Linear & Quadratic Regression · Feature Engineering |
| [**Advanced Python Projects & Exercises**](https://github.com/adrianc7/advanced-python-projects-and-exercises) | Collection of advanced Python projects including stock trading automation, cryptocurrency arbitrage detection, API ingestion, and algorithmic problem-solving with OOP design and analytical focus. | Python · REST APIs · OOP · pandas · NumPy · Matplotlib · JSON Data Processing |
| [**Inter-University Summit Project Presentation**](https://github.com/adrianc7/inter-university-summit-project-presentation) | SQL + Power BI case study demonstrating how SQL Views streamline analytics integration. Showcased performance tuning, pre-aggregation, and dashboard development for collaborative reporting. | SQL Server · T-SQL · Power BI · Data Visualization · Query Optimization |
| [**Korean Lottery (Lotto 6/45) Data Analysis**](https://github.com/adrianc7/korean-lottery-analysis) | Exploratory data analysis of Korean Lotto 6/45 draws. Investigated statistical distributions, number frequency, and randomness using Python-based analytics and data visualization techniques. | Python · pandas · matplotlib · seaborn · EDA · Probability Analysis |
| [**NBA Player Stats Pipeline (AWS RDS + S3)**](https://github.com/adrianc7/nba-player-stats-pipeline) | Built a lightweight cloud data workflow to process NBA player statistics, load data into AWS RDS (MySQL), and publish an HTML leaderboard to Amazon S3. Used Python for ETL operations and Boto3 for automated file upload and hosting setup. | Python · pandas · PyMySQL · Boto3 · AWS RDS · Amazon S3 · Static Website Hosting |

## Tableau Dashboards

Explore some of my interactive data visualizations and dashboards:

[**Tableau Public Portfolio**](https://public.tableau.com/app/profile/adrianchavezloya/vizzes)

---

## Technical Skills

**Languages:** Python, SQL, R, PySpark  
**Cloud Platforms:** AWS, Azure, Snowflake  
**Data Tools:** dbt, Databricks, Airflow, Power BI, Tableau  
**Databases:** PostgreSQL, SQL Server, BigQuery  
**Core Competencies:** Data Modeling, ETL/ELT, Pipeline Automation, Data Governance, Analytics Engineering  

---

## Connect with Me

- [LinkedIn](https://www.linkedin.com/in/adrian-chavez-loya)  
- [adrianchavezloya@gmail.com](mailto:adrianchavezloya@gmail.com)  
